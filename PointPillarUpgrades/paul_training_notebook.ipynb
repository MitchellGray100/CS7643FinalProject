{"cells":[{"cell_type":"code","execution_count":18,"id":"fdae4328","metadata":{"id":"fdae4328","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764615499471,"user_tz":300,"elapsed":4906,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"}},"outputId":"f24c63b9-3e05-49b4-cc3a-8c56ed81c6ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Current working directory: /content/drive/MyDrive/CS7643FinalProject\n"]}],"source":["import os\n","os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n","from google.colab import drive\n","\n","drive.flush_and_unmount()\n","\n","drive.mount('/content/drive', force_remount=True)\n","\n","directory_path = '/content/drive/MyDrive/CS7643FinalProject'\n","if os.path.exists(directory_path):\n","    os.chdir(directory_path)\n","    print(f\"Current working directory: {os.getcwd()}\")\n","else:\n","    print(f\"Error: Directory {directory_path} does not exist.\")"]},{"cell_type":"code","source":[],"metadata":{"id":"3Ezp0c8ddlIR","executionInfo":{"status":"ok","timestamp":1764615499504,"user_tz":300,"elapsed":24,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"}}},"id":"3Ezp0c8ddlIR","execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":19,"id":"9328af9a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4190,"status":"ok","timestamp":1764615503707,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"},"user_tz":300},"id":"9328af9a","outputId":"dd87aa09-bccb-467c-e4a7-e3774a7600fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: trimesh in /usr/local/lib/python3.12/dist-packages (4.10.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.12/dist-packages (from trimesh) (2.0.2)\n"]}],"source":["!pip install trimesh"]},{"cell_type":"code","execution_count":20,"id":"16d2fc1d","metadata":{"id":"16d2fc1d","executionInfo":{"status":"ok","timestamp":1764615503766,"user_tz":300,"elapsed":50,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"}}},"outputs":[],"source":["import torch\n","from point_pillar.pillar_model import PointPillarsClassifier\n","from point_pillar.pillar_trainer import Trainer\n","from torch.utils.data import DataLoader\n","from point_pillar.modelnet_dataset import ModelNetDataset\n","from point_pillar.modelnet_dataset import augment_pointcloud\n","from point_pillar.config import config"]},{"cell_type":"code","execution_count":21,"id":"1d0ac0b5","metadata":{"id":"1d0ac0b5","executionInfo":{"status":"ok","timestamp":1764615503785,"user_tz":300,"elapsed":8,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"}}},"outputs":[],"source":["import random\n","import numpy as np\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","    # Enforce deterministic behaviour\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","    # Extra safety for dataloader workers\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","\n","def seed_worker(worker_id):\n","    import numpy as np\n","    import random\n","    seed = 42 + worker_id\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","set_seed(42)\n"]},{"cell_type":"code","execution_count":22,"id":"944fbf27","metadata":{"executionInfo":{"elapsed":48,"status":"ok","timestamp":1764615503842,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"},"user_tz":300},"id":"944fbf27","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7bfa17d-100a-4ea5-cfd6-fd5e67e14526"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(device)"]},{"cell_type":"code","execution_count":23,"id":"de8d982a","metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1764615503872,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"},"user_tz":300},"id":"de8d982a","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1e985870-bdb7-4c1f-a185-ecf691456cf5"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'dataset': {'name': 'ModelNet40', 'num_classes': 40, 'num_points': 1024}, 'voxelizer': {'x_range': (-1.0, 1.0), 'y_range': (-1.0, 1.0), 'z_range': (-1.0, 1.0), 'pillar_size': (0.1, 0.1), 'max_pillars': 1024, 'max_points_per_pillar': 32}, 'pfn': {'in_dim': 8, 'out_dim': 64, 'hidden_dim': [64, 64], 'use_residual': True}, 'backbone': {'base_channels': 32, 'fc1_dim': 256, 'dropout_p': 0.15}, 'train': {'batch_size': 32, 'lr': 0.001, 'weight_decay': 0.0001, 'num_epochs': 80}}\n"]}],"source":["config[\"train\"][\"num_epochs\"] = 80\n","config[\"backbone\"][\"dropout_p\"] = 0.15\n","config[\"dataset\"][\"num_points\"] = 1024\n","config[\"dataset\"][\"name\"] = 'ModelNet40'\n","config[\"dataset\"][\"num_classes\"] = 40\n","print(config)"]},{"cell_type":"code","execution_count":24,"id":"92109d2c","metadata":{"executionInfo":{"elapsed":82138,"status":"ok","timestamp":1764615586019,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"},"user_tz":300},"id":"92109d2c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a63c2009-806b-4144-c2dd-710981371393"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 40 classes, 9843 samples\n","Found 40 classes, 2468 samples\n"]}],"source":["DATA_DIR = \"./data\" + \"/\" + config[\"dataset\"][\"name\"]\n","PREDATA_DIR = \"./data\" + \"/\" + config[\"dataset\"][\"name\"] + \"_precomputed_\" + str(config[\"dataset\"][\"num_points\"])\n","\n","# import os\n","# import urllib.request\n","# import tarfile\n","\n","os.makedirs(DATA_DIR, exist_ok=True)\n","\n","# MODELNET_URL = \"http://modelnet.cs.princeton.edu/ModelNet40.zip\"  # or 40\n","\n","# zip_path = f\"{DATA_DIR}/ModelNet40.zip\"\n","# if not os.path.exists(zip_path):\n","#     urllib.request.urlretrieve(MODELNET_URL, zip_path)\n","\n","# # Unzip\n","# !unzip -q \"{DATA_DIR}/ModelNet40.zip\" -d \"./data\"\n","\n","train_dataset = ModelNetDataset(\n","    root=DATA_DIR,\n","    split=\"train\",\n","    num_points=config[\"dataset\"][\"num_points\"],\n","    normalize=True,\n","    precomputed_root=PREDATA_DIR,\n","    cache_mode=\"write\",\n","    transform=augment_pointcloud\n",")\n","val_dataset = ModelNetDataset(\n","    root=DATA_DIR,\n","    split=\"test\",\n","    num_points=config[\"dataset\"][\"num_points\"],\n","    normalize=True,\n","    precomputed_root=PREDATA_DIR,\n","    cache_mode=\"write\",\n","    transform=augment_pointcloud\n",")"]},{"cell_type":"code","source":[],"metadata":{"id":"UOzuDZwXdrsR","executionInfo":{"status":"ok","timestamp":1764615586030,"user_tz":300,"elapsed":31,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"}}},"id":"UOzuDZwXdrsR","execution_count":24,"outputs":[]},{"cell_type":"code","execution_count":25,"id":"a85830bd","metadata":{"id":"a85830bd","executionInfo":{"status":"ok","timestamp":1764615586044,"user_tz":300,"elapsed":22,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"}}},"outputs":[],"source":["# for i in range(len(train_dataset)):\n","#     _ = train_dataset[i]\n","# for i in range(len(val_dataset)):\n","#     _ = val_dataset[i]"]},{"cell_type":"code","execution_count":26,"id":"feb3db98","metadata":{"id":"feb3db98","executionInfo":{"status":"ok","timestamp":1764615586179,"user_tz":300,"elapsed":139,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b41fdb8c-fa52-4d1b-bacc-8789463e57cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 40 classes, 9843 samples\n","Found 40 classes, 2468 samples\n"]}],"source":["# 1. build datasets / loaders using config\n","train_dataset = ModelNetDataset(\n","    root=DATA_DIR,\n","    split=\"train\",\n","    num_points=config[\"dataset\"][\"num_points\"],\n","    normalize=True,\n","    precomputed_root=PREDATA_DIR,\n","    cache_mode=\"load\",\n","    transform=augment_pointcloud\n",")\n","val_dataset = ModelNetDataset(\n","    root=DATA_DIR,\n","    split=\"test\",\n","    num_points=config[\"dataset\"][\"num_points\"],\n","    normalize=True,\n","    precomputed_root=PREDATA_DIR,\n","    cache_mode=\"load\",\n","    transform=augment_pointcloud\n",")"]},{"cell_type":"code","execution_count":27,"id":"6b3d46d1","metadata":{"id":"6b3d46d1","executionInfo":{"status":"ok","timestamp":1764615586197,"user_tz":300,"elapsed":9,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"}}},"outputs":[],"source":["# # 1. build datasets / loaders using config\n","# train_dataset = ModelNetDataset(\n","#     root=DATA_DIR,\n","#     split=\"train\",\n","#     num_points=config[\"dataset\"][\"num_points\"],\n","#     normalize=True,\n","#     precomputed_root=None,\n","#     cache_mode=\"load\",\n","# )\n","# val_dataset = ModelNetDataset(\n","#     root=DATA_DIR,\n","#     split=\"test\",\n","#     num_points=config[\"dataset\"][\"num_points\"],\n","#     normalize=True,\n","#     precomputed_root=None,\n","#     cache_mode=\"load\",\n","# )"]},{"cell_type":"code","execution_count":28,"id":"ea9e1c13","metadata":{"id":"ea9e1c13","executionInfo":{"status":"ok","timestamp":1764615586217,"user_tz":300,"elapsed":10,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"}}},"outputs":[],"source":["g = torch.Generator()\n","g.manual_seed(42)\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=config[\"train\"][\"batch_size\"],\n","    shuffle=True,\n","    num_workers=0,\n","    worker_init_fn=seed_worker,\n","    generator=g,\n",")\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=config[\"train\"][\"batch_size\"],\n","    shuffle=False,\n","    num_workers=0,\n","    worker_init_fn=seed_worker,\n","    generator=g,\n",")"]},{"cell_type":"code","execution_count":28,"id":"b2af3636","metadata":{"id":"b2af3636","executionInfo":{"status":"ok","timestamp":1764615586237,"user_tz":300,"elapsed":10,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":29,"id":"62819567","metadata":{"id":"62819567","executionInfo":{"status":"ok","timestamp":1764615586281,"user_tz":300,"elapsed":34,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"}}},"outputs":[],"source":["# 2. build model from config\n","model = PointPillarsClassifier(config=config, device=device)"]},{"cell_type":"code","execution_count":30,"id":"b201febb","metadata":{"id":"b201febb","executionInfo":{"status":"ok","timestamp":1764615586398,"user_tz":300,"elapsed":101,"user":{"displayName":"Mitchell Gray","userId":"12803695170202865379"}}},"outputs":[],"source":["\n","# 3. build trainer from config\n","trainer = Trainer(\n","    model=model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    device=device,\n","    config=config,\n",")"]},{"cell_type":"code","execution_count":null,"id":"9864ac1e","metadata":{"id":"9864ac1e","colab":{"base_uri":"https://localhost:8080/"},"outputId":"42f259c2-4607-4325-d6c6-4aac454bd3a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Epoch 1 Batch 0] Loss=3.7298 Acc=0.031\n","[Epoch 1 Batch 20] Loss=2.9335 Acc=0.250\n","[Epoch 1 Batch 40] Loss=2.4507 Acc=0.469\n","[Epoch 1 Batch 60] Loss=1.6637 Acc=0.594\n","[Epoch 1 Batch 80] Loss=2.0354 Acc=0.469\n","[Epoch 1 Batch 100] Loss=1.4405 Acc=0.500\n","[Epoch 1 Batch 120] Loss=1.3626 Acc=0.625\n","[Epoch 1 Batch 140] Loss=1.3031 Acc=0.594\n","[Epoch 1 Batch 160] Loss=1.0181 Acc=0.719\n","[Epoch 1 Batch 180] Loss=1.2163 Acc=0.625\n","[Epoch 1 Batch 200] Loss=1.3490 Acc=0.594\n","[Epoch 1 Batch 220] Loss=1.0817 Acc=0.656\n","[Epoch 1 Batch 240] Loss=0.8569 Acc=0.750\n","[Epoch 1 Batch 260] Loss=1.0465 Acc=0.688\n","[Epoch 1 Batch 280] Loss=1.0771 Acc=0.625\n","[Epoch 1 Batch 300] Loss=0.6365 Acc=0.719\n","--> Train Epoch 1: Loss=1.6216, Acc=0.5536\n","--> Val   Epoch 1: Loss=1.1132, Acc=0.6779\n","  [*] Saved new best model (val_acc=0.6779)\n","[Epoch 2 Batch 0] Loss=1.0467 Acc=0.656\n","[Epoch 2 Batch 20] Loss=1.0629 Acc=0.719\n","[Epoch 2 Batch 40] Loss=0.5344 Acc=0.875\n","[Epoch 2 Batch 60] Loss=1.1168 Acc=0.594\n","[Epoch 2 Batch 80] Loss=0.7834 Acc=0.781\n","[Epoch 2 Batch 100] Loss=1.1027 Acc=0.750\n","[Epoch 2 Batch 120] Loss=1.1021 Acc=0.719\n","[Epoch 2 Batch 140] Loss=0.8925 Acc=0.750\n","[Epoch 2 Batch 160] Loss=0.6844 Acc=0.781\n","[Epoch 2 Batch 180] Loss=1.0644 Acc=0.719\n","[Epoch 2 Batch 200] Loss=0.6955 Acc=0.812\n","[Epoch 2 Batch 220] Loss=0.9089 Acc=0.781\n","[Epoch 2 Batch 240] Loss=0.9522 Acc=0.656\n","[Epoch 2 Batch 260] Loss=0.5036 Acc=0.844\n","[Epoch 2 Batch 280] Loss=0.4479 Acc=0.844\n","[Epoch 2 Batch 300] Loss=0.5972 Acc=0.844\n","--> Train Epoch 2: Loss=0.9065, Acc=0.7291\n","--> Val   Epoch 2: Loss=0.8587, Acc=0.7338\n","  [*] Saved new best model (val_acc=0.7338)\n","[Epoch 3 Batch 0] Loss=0.6443 Acc=0.844\n","[Epoch 3 Batch 20] Loss=0.8686 Acc=0.781\n","[Epoch 3 Batch 40] Loss=1.3153 Acc=0.594\n","[Epoch 3 Batch 60] Loss=0.4797 Acc=0.906\n","[Epoch 3 Batch 80] Loss=0.8179 Acc=0.812\n","[Epoch 3 Batch 100] Loss=1.1563 Acc=0.625\n","[Epoch 3 Batch 120] Loss=0.7722 Acc=0.844\n","[Epoch 3 Batch 140] Loss=0.7641 Acc=0.719\n","[Epoch 3 Batch 160] Loss=0.4974 Acc=0.906\n","[Epoch 3 Batch 180] Loss=0.7386 Acc=0.688\n","[Epoch 3 Batch 200] Loss=0.4984 Acc=0.844\n","[Epoch 3 Batch 220] Loss=0.6359 Acc=0.750\n","[Epoch 3 Batch 240] Loss=0.8670 Acc=0.656\n","[Epoch 3 Batch 260] Loss=0.5091 Acc=0.812\n","[Epoch 3 Batch 280] Loss=0.5603 Acc=0.844\n","[Epoch 3 Batch 300] Loss=0.7173 Acc=0.719\n","--> Train Epoch 3: Loss=0.7659, Acc=0.7678\n","--> Val   Epoch 3: Loss=0.9665, Acc=0.6957\n","[Epoch 4 Batch 0] Loss=0.6507 Acc=0.750\n","[Epoch 4 Batch 20] Loss=0.7006 Acc=0.750\n","[Epoch 4 Batch 40] Loss=0.7913 Acc=0.812\n","[Epoch 4 Batch 60] Loss=0.4385 Acc=0.906\n","[Epoch 4 Batch 80] Loss=1.2073 Acc=0.594\n","[Epoch 4 Batch 100] Loss=0.7818 Acc=0.688\n","[Epoch 4 Batch 120] Loss=0.6897 Acc=0.750\n","[Epoch 4 Batch 140] Loss=0.7319 Acc=0.844\n","[Epoch 4 Batch 160] Loss=0.6375 Acc=0.812\n","[Epoch 4 Batch 180] Loss=0.3339 Acc=0.938\n","[Epoch 4 Batch 200] Loss=0.8886 Acc=0.812\n","[Epoch 4 Batch 220] Loss=0.3691 Acc=0.906\n","[Epoch 4 Batch 240] Loss=0.9826 Acc=0.688\n","[Epoch 4 Batch 260] Loss=1.0602 Acc=0.719\n","[Epoch 4 Batch 280] Loss=0.8807 Acc=0.719\n","[Epoch 4 Batch 300] Loss=0.3854 Acc=0.844\n","--> Train Epoch 4: Loss=0.6910, Acc=0.7911\n","--> Val   Epoch 4: Loss=0.6988, Acc=0.7966\n","  [*] Saved new best model (val_acc=0.7966)\n","[Epoch 5 Batch 0] Loss=0.3714 Acc=0.906\n","[Epoch 5 Batch 20] Loss=0.3370 Acc=0.906\n","[Epoch 5 Batch 40] Loss=0.6721 Acc=0.812\n","[Epoch 5 Batch 60] Loss=0.9173 Acc=0.688\n","[Epoch 5 Batch 80] Loss=0.6780 Acc=0.750\n","[Epoch 5 Batch 100] Loss=0.5288 Acc=0.875\n","[Epoch 5 Batch 120] Loss=0.5536 Acc=0.844\n","[Epoch 5 Batch 140] Loss=0.5142 Acc=0.844\n","[Epoch 5 Batch 160] Loss=0.6379 Acc=0.781\n","[Epoch 5 Batch 180] Loss=0.5571 Acc=0.812\n","[Epoch 5 Batch 200] Loss=0.8458 Acc=0.750\n","[Epoch 5 Batch 220] Loss=0.7243 Acc=0.812\n","[Epoch 5 Batch 240] Loss=0.5206 Acc=0.906\n","[Epoch 5 Batch 260] Loss=0.4463 Acc=0.938\n","[Epoch 5 Batch 280] Loss=0.7452 Acc=0.688\n","[Epoch 5 Batch 300] Loss=0.4867 Acc=0.844\n","--> Train Epoch 5: Loss=0.6292, Acc=0.8038\n","--> Val   Epoch 5: Loss=0.8067, Acc=0.7561\n","[Epoch 6 Batch 0] Loss=0.3760 Acc=0.906\n","[Epoch 6 Batch 20] Loss=0.7706 Acc=0.781\n","[Epoch 6 Batch 40] Loss=0.5078 Acc=0.812\n","[Epoch 6 Batch 60] Loss=0.5572 Acc=0.781\n","[Epoch 6 Batch 80] Loss=0.5295 Acc=0.906\n","[Epoch 6 Batch 100] Loss=0.4845 Acc=0.844\n","[Epoch 6 Batch 120] Loss=0.7418 Acc=0.750\n","[Epoch 6 Batch 140] Loss=0.4864 Acc=0.812\n","[Epoch 6 Batch 160] Loss=0.6714 Acc=0.750\n","[Epoch 6 Batch 180] Loss=0.5119 Acc=0.812\n","[Epoch 6 Batch 200] Loss=0.6074 Acc=0.781\n","[Epoch 6 Batch 220] Loss=0.6923 Acc=0.750\n","[Epoch 6 Batch 240] Loss=0.5494 Acc=0.844\n","[Epoch 6 Batch 260] Loss=0.6855 Acc=0.750\n","[Epoch 6 Batch 280] Loss=0.7299 Acc=0.781\n","[Epoch 6 Batch 300] Loss=0.4919 Acc=0.906\n","--> Train Epoch 6: Loss=0.5923, Acc=0.8117\n","--> Val   Epoch 6: Loss=0.6556, Acc=0.7946\n","[Epoch 7 Batch 0] Loss=0.5587 Acc=0.781\n","[Epoch 7 Batch 20] Loss=0.4765 Acc=0.875\n","[Epoch 7 Batch 40] Loss=0.7456 Acc=0.812\n","[Epoch 7 Batch 60] Loss=0.6141 Acc=0.781\n","[Epoch 7 Batch 80] Loss=0.6189 Acc=0.844\n","[Epoch 7 Batch 100] Loss=0.5904 Acc=0.844\n","[Epoch 7 Batch 120] Loss=0.9232 Acc=0.719\n","[Epoch 7 Batch 140] Loss=0.6818 Acc=0.781\n","[Epoch 7 Batch 160] Loss=0.2059 Acc=0.969\n","[Epoch 7 Batch 180] Loss=0.8687 Acc=0.906\n","[Epoch 7 Batch 200] Loss=0.5160 Acc=0.781\n","[Epoch 7 Batch 220] Loss=0.4706 Acc=0.844\n","[Epoch 7 Batch 240] Loss=0.5104 Acc=0.812\n","[Epoch 7 Batch 260] Loss=0.4569 Acc=0.844\n","[Epoch 7 Batch 280] Loss=0.7972 Acc=0.688\n","[Epoch 7 Batch 300] Loss=0.4417 Acc=0.812\n","--> Train Epoch 7: Loss=0.5608, Acc=0.8234\n","--> Val   Epoch 7: Loss=0.7048, Acc=0.7950\n","[Epoch 8 Batch 0] Loss=0.6419 Acc=0.781\n","[Epoch 8 Batch 20] Loss=0.2864 Acc=0.969\n","[Epoch 8 Batch 40] Loss=0.8324 Acc=0.750\n","[Epoch 8 Batch 60] Loss=0.3477 Acc=0.875\n","[Epoch 8 Batch 80] Loss=0.3833 Acc=0.906\n","[Epoch 8 Batch 100] Loss=0.4822 Acc=0.844\n","[Epoch 8 Batch 120] Loss=0.9718 Acc=0.750\n","[Epoch 8 Batch 140] Loss=0.4061 Acc=0.906\n","[Epoch 8 Batch 160] Loss=0.3284 Acc=0.906\n","[Epoch 8 Batch 180] Loss=0.3983 Acc=0.969\n","[Epoch 8 Batch 200] Loss=0.5461 Acc=0.812\n","[Epoch 8 Batch 220] Loss=0.6178 Acc=0.781\n","[Epoch 8 Batch 240] Loss=0.2420 Acc=0.938\n","[Epoch 8 Batch 260] Loss=0.8403 Acc=0.750\n","[Epoch 8 Batch 280] Loss=0.4855 Acc=0.812\n","[Epoch 8 Batch 300] Loss=0.5246 Acc=0.781\n","--> Train Epoch 8: Loss=0.5372, Acc=0.8306\n","--> Val   Epoch 8: Loss=0.6877, Acc=0.7913\n","[Epoch 9 Batch 0] Loss=0.4507 Acc=0.875\n","[Epoch 9 Batch 20] Loss=0.3631 Acc=0.875\n","[Epoch 9 Batch 40] Loss=0.5596 Acc=0.844\n","[Epoch 9 Batch 60] Loss=0.3328 Acc=0.906\n","[Epoch 9 Batch 80] Loss=1.0017 Acc=0.719\n","[Epoch 9 Batch 100] Loss=0.8327 Acc=0.719\n","[Epoch 9 Batch 120] Loss=0.6475 Acc=0.844\n","[Epoch 9 Batch 140] Loss=0.3302 Acc=0.875\n","[Epoch 9 Batch 160] Loss=0.6587 Acc=0.750\n","[Epoch 9 Batch 180] Loss=0.3768 Acc=0.812\n","[Epoch 9 Batch 200] Loss=0.5574 Acc=0.812\n","[Epoch 9 Batch 220] Loss=0.4170 Acc=0.781\n","[Epoch 9 Batch 240] Loss=0.4637 Acc=0.875\n","[Epoch 9 Batch 260] Loss=0.2900 Acc=0.938\n","[Epoch 9 Batch 280] Loss=0.6336 Acc=0.844\n","[Epoch 9 Batch 300] Loss=0.2864 Acc=0.938\n","--> Train Epoch 9: Loss=0.5104, Acc=0.8348\n","--> Val   Epoch 9: Loss=0.6701, Acc=0.7966\n","[Epoch 10 Batch 0] Loss=0.6539 Acc=0.812\n","[Epoch 10 Batch 20] Loss=0.3720 Acc=0.844\n","[Epoch 10 Batch 40] Loss=0.2269 Acc=0.938\n","[Epoch 10 Batch 60] Loss=0.3271 Acc=0.906\n","[Epoch 10 Batch 80] Loss=0.7596 Acc=0.781\n","[Epoch 10 Batch 100] Loss=0.7150 Acc=0.750\n","[Epoch 10 Batch 120] Loss=0.6757 Acc=0.781\n","[Epoch 10 Batch 140] Loss=0.4209 Acc=0.875\n","[Epoch 10 Batch 160] Loss=0.5896 Acc=0.781\n","[Epoch 10 Batch 180] Loss=0.3831 Acc=0.875\n","[Epoch 10 Batch 200] Loss=0.3876 Acc=0.906\n","[Epoch 10 Batch 220] Loss=0.7859 Acc=0.750\n","[Epoch 10 Batch 240] Loss=0.8667 Acc=0.781\n","[Epoch 10 Batch 260] Loss=0.5898 Acc=0.812\n","[Epoch 10 Batch 280] Loss=0.4558 Acc=0.844\n","[Epoch 10 Batch 300] Loss=0.5350 Acc=0.844\n","--> Train Epoch 10: Loss=0.4906, Acc=0.8445\n","--> Val   Epoch 10: Loss=0.6565, Acc=0.8096\n","  [*] Saved new best model (val_acc=0.8096)\n","[Epoch 11 Batch 0] Loss=0.6164 Acc=0.781\n","[Epoch 11 Batch 20] Loss=0.4201 Acc=0.812\n","[Epoch 11 Batch 40] Loss=0.4210 Acc=0.844\n","[Epoch 11 Batch 60] Loss=0.3074 Acc=0.844\n","[Epoch 11 Batch 80] Loss=0.4161 Acc=0.906\n","[Epoch 11 Batch 100] Loss=0.3553 Acc=0.875\n","[Epoch 11 Batch 120] Loss=0.7092 Acc=0.812\n","[Epoch 11 Batch 140] Loss=0.3559 Acc=0.875\n","[Epoch 11 Batch 160] Loss=0.3538 Acc=0.812\n","[Epoch 11 Batch 180] Loss=0.3346 Acc=0.906\n","[Epoch 11 Batch 200] Loss=0.4215 Acc=0.906\n","[Epoch 11 Batch 220] Loss=0.4831 Acc=0.844\n","[Epoch 11 Batch 240] Loss=0.3107 Acc=0.906\n","[Epoch 11 Batch 260] Loss=0.8204 Acc=0.781\n","[Epoch 11 Batch 280] Loss=0.8440 Acc=0.750\n","[Epoch 11 Batch 300] Loss=0.8741 Acc=0.656\n","--> Train Epoch 11: Loss=0.4756, Acc=0.8473\n","--> Val   Epoch 11: Loss=0.6303, Acc=0.7958\n","[Epoch 12 Batch 0] Loss=0.7364 Acc=0.750\n","[Epoch 12 Batch 20] Loss=0.3479 Acc=0.844\n","[Epoch 12 Batch 40] Loss=0.4824 Acc=0.844\n","[Epoch 12 Batch 60] Loss=0.4824 Acc=0.844\n","[Epoch 12 Batch 80] Loss=0.6264 Acc=0.875\n","[Epoch 12 Batch 100] Loss=0.2222 Acc=0.875\n","[Epoch 12 Batch 120] Loss=0.0488 Acc=1.000\n","[Epoch 12 Batch 140] Loss=0.4782 Acc=0.875\n","[Epoch 12 Batch 160] Loss=0.4275 Acc=0.875\n","[Epoch 12 Batch 180] Loss=0.5366 Acc=0.875\n","[Epoch 12 Batch 200] Loss=0.3300 Acc=0.875\n","[Epoch 12 Batch 220] Loss=0.2661 Acc=0.844\n","[Epoch 12 Batch 240] Loss=0.6596 Acc=0.844\n","[Epoch 12 Batch 260] Loss=0.2653 Acc=0.875\n","[Epoch 12 Batch 280] Loss=0.1946 Acc=0.938\n","[Epoch 12 Batch 300] Loss=0.3253 Acc=0.875\n","--> Train Epoch 12: Loss=0.4566, Acc=0.8548\n","--> Val   Epoch 12: Loss=0.6040, Acc=0.8152\n","  [*] Saved new best model (val_acc=0.8152)\n","[Epoch 13 Batch 0] Loss=0.4732 Acc=0.875\n","[Epoch 13 Batch 20] Loss=0.4248 Acc=0.906\n","[Epoch 13 Batch 40] Loss=0.2756 Acc=0.875\n","[Epoch 13 Batch 60] Loss=0.3229 Acc=0.906\n","[Epoch 13 Batch 80] Loss=0.2388 Acc=0.875\n","[Epoch 13 Batch 100] Loss=0.9123 Acc=0.750\n","[Epoch 13 Batch 120] Loss=0.8023 Acc=0.750\n","[Epoch 13 Batch 140] Loss=0.2880 Acc=0.938\n","[Epoch 13 Batch 160] Loss=0.3189 Acc=0.875\n","[Epoch 13 Batch 180] Loss=0.3675 Acc=0.906\n","[Epoch 13 Batch 200] Loss=0.2134 Acc=0.969\n","[Epoch 13 Batch 220] Loss=0.3317 Acc=0.938\n","[Epoch 13 Batch 240] Loss=0.5014 Acc=0.812\n","[Epoch 13 Batch 260] Loss=0.4541 Acc=0.875\n","[Epoch 13 Batch 280] Loss=0.1116 Acc=0.969\n","[Epoch 13 Batch 300] Loss=0.5687 Acc=0.812\n","--> Train Epoch 13: Loss=0.4594, Acc=0.8517\n","--> Val   Epoch 13: Loss=0.6110, Acc=0.8023\n","[Epoch 14 Batch 0] Loss=0.5399 Acc=0.781\n","[Epoch 14 Batch 20] Loss=0.6007 Acc=0.781\n","[Epoch 14 Batch 40] Loss=0.2785 Acc=0.938\n","[Epoch 14 Batch 60] Loss=0.4306 Acc=0.906\n","[Epoch 14 Batch 80] Loss=0.3840 Acc=0.906\n","[Epoch 14 Batch 100] Loss=0.8016 Acc=0.719\n","[Epoch 14 Batch 120] Loss=0.2488 Acc=0.938\n","[Epoch 14 Batch 140] Loss=0.5861 Acc=0.812\n","[Epoch 14 Batch 160] Loss=0.2796 Acc=0.938\n","[Epoch 14 Batch 180] Loss=0.4331 Acc=0.812\n","[Epoch 14 Batch 200] Loss=0.4697 Acc=0.844\n","[Epoch 14 Batch 220] Loss=0.4322 Acc=0.812\n","[Epoch 14 Batch 240] Loss=0.2371 Acc=0.875\n","[Epoch 14 Batch 260] Loss=0.6378 Acc=0.812\n","[Epoch 14 Batch 280] Loss=0.6398 Acc=0.812\n","[Epoch 14 Batch 300] Loss=0.3900 Acc=0.875\n","--> Train Epoch 14: Loss=0.4248, Acc=0.8609\n","--> Val   Epoch 14: Loss=0.5903, Acc=0.8165\n","  [*] Saved new best model (val_acc=0.8165)\n","[Epoch 15 Batch 0] Loss=0.3718 Acc=0.875\n","[Epoch 15 Batch 20] Loss=0.1981 Acc=0.938\n","[Epoch 15 Batch 40] Loss=0.1961 Acc=0.969\n","[Epoch 15 Batch 60] Loss=0.4380 Acc=0.875\n","[Epoch 15 Batch 80] Loss=0.3328 Acc=0.938\n","[Epoch 15 Batch 100] Loss=0.3369 Acc=0.875\n","[Epoch 15 Batch 120] Loss=0.4005 Acc=0.906\n","[Epoch 15 Batch 140] Loss=0.3495 Acc=0.938\n","[Epoch 15 Batch 160] Loss=0.3694 Acc=0.906\n","[Epoch 15 Batch 180] Loss=0.3446 Acc=0.875\n","[Epoch 15 Batch 200] Loss=0.5062 Acc=0.781\n","[Epoch 15 Batch 220] Loss=0.5128 Acc=0.875\n","[Epoch 15 Batch 240] Loss=0.2672 Acc=0.906\n","[Epoch 15 Batch 260] Loss=0.4020 Acc=0.844\n","[Epoch 15 Batch 280] Loss=1.0847 Acc=0.688\n","[Epoch 15 Batch 300] Loss=0.4412 Acc=0.875\n","--> Train Epoch 15: Loss=0.4201, Acc=0.8618\n","--> Val   Epoch 15: Loss=0.6009, Acc=0.8075\n","[Epoch 16 Batch 0] Loss=0.3368 Acc=0.875\n","[Epoch 16 Batch 20] Loss=0.2163 Acc=0.938\n","[Epoch 16 Batch 40] Loss=0.1995 Acc=0.938\n","[Epoch 16 Batch 60] Loss=0.2099 Acc=0.938\n","[Epoch 16 Batch 80] Loss=0.4009 Acc=0.875\n","[Epoch 16 Batch 100] Loss=0.2760 Acc=0.938\n","[Epoch 16 Batch 120] Loss=0.4006 Acc=0.844\n","[Epoch 16 Batch 140] Loss=0.3390 Acc=0.875\n","[Epoch 16 Batch 160] Loss=0.3588 Acc=0.875\n","[Epoch 16 Batch 180] Loss=0.3616 Acc=0.875\n","[Epoch 16 Batch 200] Loss=0.5879 Acc=0.781\n","[Epoch 16 Batch 220] Loss=0.5010 Acc=0.906\n","[Epoch 16 Batch 240] Loss=0.5703 Acc=0.781\n","[Epoch 16 Batch 260] Loss=0.3984 Acc=0.938\n","[Epoch 16 Batch 280] Loss=0.4032 Acc=0.812\n","[Epoch 16 Batch 300] Loss=0.5102 Acc=0.875\n","--> Train Epoch 16: Loss=0.4097, Acc=0.8649\n","--> Val   Epoch 16: Loss=0.6224, Acc=0.8148\n","[Epoch 17 Batch 0] Loss=0.4305 Acc=0.781\n","[Epoch 17 Batch 20] Loss=0.3667 Acc=0.906\n","[Epoch 17 Batch 40] Loss=0.2742 Acc=0.875\n","[Epoch 17 Batch 60] Loss=0.5313 Acc=0.812\n","[Epoch 17 Batch 80] Loss=0.3314 Acc=0.875\n","[Epoch 17 Batch 100] Loss=0.5092 Acc=0.812\n","[Epoch 17 Batch 120] Loss=0.6376 Acc=0.812\n","[Epoch 17 Batch 140] Loss=0.4273 Acc=0.812\n","[Epoch 17 Batch 160] Loss=0.7739 Acc=0.812\n","[Epoch 17 Batch 180] Loss=0.3896 Acc=0.844\n","[Epoch 17 Batch 200] Loss=0.3110 Acc=0.906\n","[Epoch 17 Batch 220] Loss=0.4798 Acc=0.875\n","[Epoch 17 Batch 240] Loss=0.6652 Acc=0.812\n","[Epoch 17 Batch 260] Loss=0.2837 Acc=0.906\n","[Epoch 17 Batch 280] Loss=0.1622 Acc=0.969\n","[Epoch 17 Batch 300] Loss=0.3897 Acc=0.906\n","--> Train Epoch 17: Loss=0.3976, Acc=0.8683\n","--> Val   Epoch 17: Loss=0.5775, Acc=0.8258\n","  [*] Saved new best model (val_acc=0.8258)\n","[Epoch 18 Batch 0] Loss=0.1695 Acc=0.969\n","[Epoch 18 Batch 20] Loss=0.2761 Acc=0.906\n","[Epoch 18 Batch 40] Loss=0.2935 Acc=0.875\n","[Epoch 18 Batch 60] Loss=0.5270 Acc=0.875\n","[Epoch 18 Batch 80] Loss=0.4211 Acc=0.844\n","[Epoch 18 Batch 100] Loss=0.2087 Acc=0.906\n","[Epoch 18 Batch 120] Loss=0.2857 Acc=0.875\n","[Epoch 18 Batch 140] Loss=0.4107 Acc=0.812\n","[Epoch 18 Batch 160] Loss=0.5784 Acc=0.812\n","[Epoch 18 Batch 180] Loss=0.4296 Acc=0.812\n","[Epoch 18 Batch 200] Loss=0.8325 Acc=0.750\n","[Epoch 18 Batch 220] Loss=0.4032 Acc=0.844\n","[Epoch 18 Batch 240] Loss=0.6437 Acc=0.844\n","[Epoch 18 Batch 260] Loss=0.4936 Acc=0.812\n","[Epoch 18 Batch 280] Loss=0.6206 Acc=0.875\n","[Epoch 18 Batch 300] Loss=0.3646 Acc=0.906\n","--> Train Epoch 18: Loss=0.3869, Acc=0.8742\n","--> Val   Epoch 18: Loss=0.5912, Acc=0.8124\n","[Epoch 19 Batch 0] Loss=0.3456 Acc=0.844\n","[Epoch 19 Batch 20] Loss=0.3977 Acc=0.906\n","[Epoch 19 Batch 40] Loss=0.3129 Acc=0.844\n","[Epoch 19 Batch 60] Loss=0.3815 Acc=0.844\n","[Epoch 19 Batch 80] Loss=0.2961 Acc=0.875\n","[Epoch 19 Batch 100] Loss=0.3796 Acc=0.875\n","[Epoch 19 Batch 120] Loss=0.1874 Acc=0.906\n","[Epoch 19 Batch 140] Loss=0.6242 Acc=0.812\n","[Epoch 19 Batch 160] Loss=0.3434 Acc=0.844\n","[Epoch 19 Batch 180] Loss=0.3913 Acc=0.906\n","[Epoch 19 Batch 200] Loss=0.4671 Acc=0.844\n","[Epoch 19 Batch 220] Loss=0.2550 Acc=0.906\n","[Epoch 19 Batch 240] Loss=0.3137 Acc=0.938\n","[Epoch 19 Batch 260] Loss=0.5545 Acc=0.844\n","[Epoch 19 Batch 280] Loss=0.3299 Acc=0.875\n","[Epoch 19 Batch 300] Loss=0.6680 Acc=0.781\n","--> Train Epoch 19: Loss=0.3859, Acc=0.8717\n","--> Val   Epoch 19: Loss=0.5604, Acc=0.8274\n","  [*] Saved new best model (val_acc=0.8274)\n","[Epoch 20 Batch 0] Loss=0.2676 Acc=0.906\n","[Epoch 20 Batch 20] Loss=0.6344 Acc=0.750\n","[Epoch 20 Batch 40] Loss=0.3708 Acc=0.938\n","[Epoch 20 Batch 60] Loss=0.5168 Acc=0.750\n","[Epoch 20 Batch 80] Loss=0.2279 Acc=0.938\n","[Epoch 20 Batch 100] Loss=0.8788 Acc=0.656\n","[Epoch 20 Batch 120] Loss=0.2182 Acc=0.906\n","[Epoch 20 Batch 140] Loss=0.4144 Acc=0.750\n","[Epoch 20 Batch 160] Loss=0.3018 Acc=0.938\n","[Epoch 20 Batch 180] Loss=0.2594 Acc=0.906\n","[Epoch 20 Batch 200] Loss=0.4324 Acc=0.875\n","[Epoch 20 Batch 220] Loss=0.3851 Acc=0.906\n","[Epoch 20 Batch 240] Loss=0.4022 Acc=0.906\n","[Epoch 20 Batch 260] Loss=0.3424 Acc=0.875\n","[Epoch 20 Batch 280] Loss=0.2865 Acc=0.875\n","[Epoch 20 Batch 300] Loss=0.3629 Acc=0.906\n","--> Train Epoch 20: Loss=0.3723, Acc=0.8750\n","--> Val   Epoch 20: Loss=0.5749, Acc=0.8254\n","[Epoch 21 Batch 0] Loss=0.3082 Acc=0.875\n","[Epoch 21 Batch 20] Loss=0.2450 Acc=0.875\n","[Epoch 21 Batch 40] Loss=0.3106 Acc=0.906\n","[Epoch 21 Batch 60] Loss=0.1783 Acc=0.938\n","[Epoch 21 Batch 80] Loss=0.3400 Acc=0.875\n","[Epoch 21 Batch 100] Loss=0.4466 Acc=0.875\n","[Epoch 21 Batch 120] Loss=0.1964 Acc=0.938\n","[Epoch 21 Batch 140] Loss=0.3935 Acc=0.844\n","[Epoch 21 Batch 160] Loss=0.3412 Acc=0.844\n","[Epoch 21 Batch 180] Loss=0.2440 Acc=0.875\n","[Epoch 21 Batch 200] Loss=0.1240 Acc=0.938\n","[Epoch 21 Batch 220] Loss=0.4711 Acc=0.875\n","[Epoch 21 Batch 240] Loss=0.2973 Acc=0.875\n","[Epoch 21 Batch 260] Loss=0.6149 Acc=0.844\n","[Epoch 21 Batch 280] Loss=0.5201 Acc=0.875\n","[Epoch 21 Batch 300] Loss=0.3609 Acc=0.875\n","--> Train Epoch 21: Loss=0.3657, Acc=0.8770\n","--> Val   Epoch 21: Loss=0.5814, Acc=0.8294\n","  [*] Saved new best model (val_acc=0.8294)\n","[Epoch 22 Batch 0] Loss=0.2807 Acc=0.875\n","[Epoch 22 Batch 20] Loss=0.2544 Acc=0.906\n","[Epoch 22 Batch 40] Loss=0.1077 Acc=0.969\n","[Epoch 22 Batch 60] Loss=0.6107 Acc=0.875\n","[Epoch 22 Batch 80] Loss=0.4625 Acc=0.844\n","[Epoch 22 Batch 100] Loss=0.2256 Acc=0.938\n","[Epoch 22 Batch 120] Loss=0.1029 Acc=0.969\n","[Epoch 22 Batch 140] Loss=0.1564 Acc=0.938\n","[Epoch 22 Batch 160] Loss=0.3435 Acc=0.906\n","[Epoch 22 Batch 180] Loss=0.1607 Acc=0.938\n","[Epoch 22 Batch 200] Loss=0.3672 Acc=0.812\n","[Epoch 22 Batch 220] Loss=0.4210 Acc=0.812\n","[Epoch 22 Batch 240] Loss=0.3751 Acc=0.906\n","[Epoch 22 Batch 260] Loss=0.3062 Acc=0.875\n","[Epoch 22 Batch 280] Loss=0.4319 Acc=0.812\n","[Epoch 22 Batch 300] Loss=0.1662 Acc=0.938\n","--> Train Epoch 22: Loss=0.3584, Acc=0.8777\n","--> Val   Epoch 22: Loss=0.5915, Acc=0.8351\n","  [*] Saved new best model (val_acc=0.8351)\n","[Epoch 23 Batch 0] Loss=0.3058 Acc=0.938\n","[Epoch 23 Batch 20] Loss=0.1720 Acc=0.938\n","[Epoch 23 Batch 40] Loss=0.2747 Acc=0.906\n","[Epoch 23 Batch 60] Loss=0.4630 Acc=0.812\n","[Epoch 23 Batch 80] Loss=0.4099 Acc=0.875\n","[Epoch 23 Batch 100] Loss=0.3206 Acc=0.938\n","[Epoch 23 Batch 120] Loss=0.2619 Acc=0.906\n","[Epoch 23 Batch 140] Loss=0.3213 Acc=0.938\n","[Epoch 23 Batch 160] Loss=0.2727 Acc=0.906\n","[Epoch 23 Batch 180] Loss=0.2165 Acc=0.906\n","[Epoch 23 Batch 200] Loss=0.4139 Acc=0.781\n","[Epoch 23 Batch 220] Loss=0.3701 Acc=0.875\n","[Epoch 23 Batch 240] Loss=0.5655 Acc=0.812\n","[Epoch 23 Batch 260] Loss=0.4948 Acc=0.781\n","[Epoch 23 Batch 280] Loss=0.2969 Acc=0.906\n","[Epoch 23 Batch 300] Loss=0.3063 Acc=0.906\n","--> Train Epoch 23: Loss=0.3553, Acc=0.8783\n","--> Val   Epoch 23: Loss=0.6175, Acc=0.8156\n","[Epoch 24 Batch 0] Loss=0.2943 Acc=0.938\n","[Epoch 24 Batch 20] Loss=0.2245 Acc=0.938\n","[Epoch 24 Batch 40] Loss=0.3504 Acc=0.844\n","[Epoch 24 Batch 60] Loss=0.4282 Acc=0.875\n","[Epoch 24 Batch 80] Loss=0.2347 Acc=0.875\n","[Epoch 24 Batch 100] Loss=0.4293 Acc=0.906\n","[Epoch 24 Batch 120] Loss=0.3218 Acc=0.906\n","[Epoch 24 Batch 140] Loss=0.3086 Acc=0.906\n","[Epoch 24 Batch 160] Loss=0.4809 Acc=0.812\n","[Epoch 24 Batch 180] Loss=0.3269 Acc=0.844\n","[Epoch 24 Batch 200] Loss=0.3720 Acc=0.781\n","[Epoch 24 Batch 220] Loss=0.3619 Acc=0.875\n","[Epoch 24 Batch 240] Loss=0.2450 Acc=0.969\n","[Epoch 24 Batch 260] Loss=0.4924 Acc=0.875\n","[Epoch 24 Batch 280] Loss=0.3672 Acc=0.875\n","[Epoch 24 Batch 300] Loss=0.5695 Acc=0.844\n","--> Train Epoch 24: Loss=0.3546, Acc=0.8817\n","--> Val   Epoch 24: Loss=0.5524, Acc=0.8335\n","[Epoch 25 Batch 0] Loss=0.2201 Acc=0.938\n","[Epoch 25 Batch 20] Loss=0.3751 Acc=0.812\n","[Epoch 25 Batch 40] Loss=0.2851 Acc=0.906\n","[Epoch 25 Batch 60] Loss=0.2348 Acc=0.938\n","[Epoch 25 Batch 80] Loss=0.2967 Acc=0.938\n","[Epoch 25 Batch 100] Loss=0.3496 Acc=0.812\n","[Epoch 25 Batch 120] Loss=0.2814 Acc=0.875\n","[Epoch 25 Batch 140] Loss=0.4335 Acc=0.781\n","[Epoch 25 Batch 160] Loss=0.0909 Acc=0.969\n","[Epoch 25 Batch 180] Loss=0.2707 Acc=0.906\n","[Epoch 25 Batch 200] Loss=0.4592 Acc=0.812\n","[Epoch 25 Batch 220] Loss=0.2942 Acc=0.906\n","[Epoch 25 Batch 240] Loss=0.5828 Acc=0.844\n","[Epoch 25 Batch 260] Loss=0.4119 Acc=0.844\n","[Epoch 25 Batch 280] Loss=0.2440 Acc=0.969\n","[Epoch 25 Batch 300] Loss=0.4443 Acc=0.781\n","--> Train Epoch 25: Loss=0.3396, Acc=0.8862\n","--> Val   Epoch 25: Loss=0.5470, Acc=0.8367\n","  [*] Saved new best model (val_acc=0.8367)\n","[Epoch 26 Batch 0] Loss=0.4411 Acc=0.844\n","[Epoch 26 Batch 20] Loss=0.0943 Acc=0.969\n","[Epoch 26 Batch 40] Loss=0.1400 Acc=0.969\n","[Epoch 26 Batch 60] Loss=0.0750 Acc=0.969\n","[Epoch 26 Batch 80] Loss=0.2721 Acc=0.875\n","[Epoch 26 Batch 100] Loss=0.2670 Acc=0.844\n","[Epoch 26 Batch 120] Loss=0.1931 Acc=0.969\n","[Epoch 26 Batch 140] Loss=0.4487 Acc=0.812\n","[Epoch 26 Batch 160] Loss=0.5920 Acc=0.781\n","[Epoch 26 Batch 180] Loss=0.1935 Acc=0.906\n","[Epoch 26 Batch 200] Loss=0.2772 Acc=0.906\n","[Epoch 26 Batch 220] Loss=0.2147 Acc=0.906\n","[Epoch 26 Batch 240] Loss=0.3371 Acc=0.875\n","[Epoch 26 Batch 260] Loss=0.3967 Acc=0.875\n","[Epoch 26 Batch 280] Loss=0.1306 Acc=0.969\n","[Epoch 26 Batch 300] Loss=0.4166 Acc=0.875\n","--> Train Epoch 26: Loss=0.3298, Acc=0.8891\n","--> Val   Epoch 26: Loss=0.6412, Acc=0.8104\n","[Epoch 27 Batch 0] Loss=0.0738 Acc=1.000\n","[Epoch 27 Batch 20] Loss=0.3233 Acc=0.875\n","[Epoch 27 Batch 40] Loss=0.2187 Acc=0.938\n","[Epoch 27 Batch 60] Loss=0.4868 Acc=0.750\n","[Epoch 27 Batch 80] Loss=0.1451 Acc=0.969\n","[Epoch 27 Batch 100] Loss=0.2833 Acc=0.906\n","[Epoch 27 Batch 120] Loss=0.1268 Acc=0.969\n","[Epoch 27 Batch 140] Loss=0.2433 Acc=0.969\n","[Epoch 27 Batch 160] Loss=0.2048 Acc=0.906\n","[Epoch 27 Batch 180] Loss=0.3218 Acc=0.938\n","[Epoch 27 Batch 200] Loss=0.5217 Acc=0.875\n","[Epoch 27 Batch 220] Loss=0.5398 Acc=0.844\n","[Epoch 27 Batch 240] Loss=0.4586 Acc=0.875\n","[Epoch 27 Batch 260] Loss=0.4379 Acc=0.906\n","[Epoch 27 Batch 280] Loss=0.3872 Acc=0.844\n","[Epoch 27 Batch 300] Loss=0.2253 Acc=0.875\n","--> Train Epoch 27: Loss=0.3214, Acc=0.8917\n","--> Val   Epoch 27: Loss=0.6202, Acc=0.8173\n","[Epoch 28 Batch 0] Loss=0.2315 Acc=0.938\n","[Epoch 28 Batch 20] Loss=0.6503 Acc=0.719\n","[Epoch 28 Batch 40] Loss=0.4645 Acc=0.812\n","[Epoch 28 Batch 60] Loss=0.4948 Acc=0.781\n","[Epoch 28 Batch 80] Loss=0.1950 Acc=0.938\n","[Epoch 28 Batch 100] Loss=0.2374 Acc=0.906\n","[Epoch 28 Batch 120] Loss=0.3177 Acc=0.844\n","[Epoch 28 Batch 140] Loss=0.2555 Acc=0.906\n","[Epoch 28 Batch 160] Loss=0.1970 Acc=0.969\n","[Epoch 28 Batch 180] Loss=0.2022 Acc=0.906\n","[Epoch 28 Batch 200] Loss=0.1529 Acc=0.938\n","[Epoch 28 Batch 220] Loss=0.3195 Acc=0.938\n","[Epoch 28 Batch 240] Loss=0.4537 Acc=0.812\n","[Epoch 28 Batch 260] Loss=0.3323 Acc=0.938\n","[Epoch 28 Batch 280] Loss=0.4771 Acc=0.812\n","[Epoch 28 Batch 300] Loss=0.8276 Acc=0.781\n","--> Train Epoch 28: Loss=0.3236, Acc=0.8886\n","--> Val   Epoch 28: Loss=0.5588, Acc=0.8310\n","[Epoch 29 Batch 0] Loss=0.4821 Acc=0.812\n","[Epoch 29 Batch 20] Loss=0.4373 Acc=0.875\n","[Epoch 29 Batch 40] Loss=0.3587 Acc=0.906\n","[Epoch 29 Batch 60] Loss=0.4912 Acc=0.844\n","[Epoch 29 Batch 80] Loss=0.4218 Acc=0.812\n","[Epoch 29 Batch 100] Loss=0.0847 Acc=1.000\n","[Epoch 29 Batch 120] Loss=0.2398 Acc=0.938\n","[Epoch 29 Batch 140] Loss=0.2969 Acc=0.844\n","[Epoch 29 Batch 160] Loss=0.3496 Acc=0.812\n","[Epoch 29 Batch 180] Loss=0.1290 Acc=0.969\n","[Epoch 29 Batch 200] Loss=0.3947 Acc=0.844\n","[Epoch 29 Batch 220] Loss=0.2963 Acc=0.938\n","[Epoch 29 Batch 240] Loss=0.7372 Acc=0.812\n","[Epoch 29 Batch 260] Loss=0.5302 Acc=0.906\n","[Epoch 29 Batch 280] Loss=0.3256 Acc=0.844\n","[Epoch 29 Batch 300] Loss=0.1402 Acc=0.969\n","--> Train Epoch 29: Loss=0.3197, Acc=0.8904\n","--> Val   Epoch 29: Loss=0.5410, Acc=0.8456\n","  [*] Saved new best model (val_acc=0.8456)\n","[Epoch 30 Batch 0] Loss=0.1906 Acc=0.938\n","[Epoch 30 Batch 20] Loss=0.4854 Acc=0.812\n","[Epoch 30 Batch 40] Loss=0.3930 Acc=0.875\n","[Epoch 30 Batch 60] Loss=0.2100 Acc=0.906\n","[Epoch 30 Batch 80] Loss=0.5495 Acc=0.781\n","[Epoch 30 Batch 100] Loss=0.3512 Acc=0.812\n","[Epoch 30 Batch 120] Loss=0.3008 Acc=0.844\n","[Epoch 30 Batch 140] Loss=0.4160 Acc=0.812\n","[Epoch 30 Batch 160] Loss=0.3679 Acc=0.875\n","[Epoch 30 Batch 180] Loss=0.4260 Acc=0.906\n","[Epoch 30 Batch 200] Loss=0.2302 Acc=0.906\n","[Epoch 30 Batch 220] Loss=0.3735 Acc=0.938\n","[Epoch 30 Batch 240] Loss=0.2204 Acc=0.906\n","[Epoch 30 Batch 260] Loss=0.2647 Acc=0.906\n","[Epoch 30 Batch 280] Loss=0.1312 Acc=0.938\n","[Epoch 30 Batch 300] Loss=0.5968 Acc=0.844\n","--> Train Epoch 30: Loss=0.3098, Acc=0.8946\n","--> Val   Epoch 30: Loss=0.5430, Acc=0.8460\n","  [*] Saved new best model (val_acc=0.8460)\n","[Epoch 31 Batch 0] Loss=0.4246 Acc=0.844\n","[Epoch 31 Batch 20] Loss=0.1308 Acc=0.969\n","[Epoch 31 Batch 40] Loss=0.2513 Acc=0.906\n","[Epoch 31 Batch 60] Loss=0.2514 Acc=0.906\n","[Epoch 31 Batch 80] Loss=0.6216 Acc=0.781\n","[Epoch 31 Batch 100] Loss=0.4178 Acc=0.812\n","[Epoch 31 Batch 120] Loss=0.1515 Acc=0.938\n","[Epoch 31 Batch 140] Loss=0.5027 Acc=0.812\n","[Epoch 31 Batch 160] Loss=0.4411 Acc=0.781\n","[Epoch 31 Batch 180] Loss=0.5937 Acc=0.781\n","[Epoch 31 Batch 200] Loss=0.3442 Acc=0.875\n","[Epoch 31 Batch 220] Loss=0.1970 Acc=0.969\n","[Epoch 31 Batch 240] Loss=0.2727 Acc=0.906\n","[Epoch 31 Batch 260] Loss=0.3755 Acc=0.875\n","[Epoch 31 Batch 280] Loss=0.6574 Acc=0.875\n","[Epoch 31 Batch 300] Loss=0.4381 Acc=0.812\n","--> Train Epoch 31: Loss=0.3055, Acc=0.8947\n","--> Val   Epoch 31: Loss=0.5166, Acc=0.8448\n","[Epoch 32 Batch 0] Loss=0.2506 Acc=0.938\n","[Epoch 32 Batch 20] Loss=0.1350 Acc=0.969\n","[Epoch 32 Batch 40] Loss=0.3585 Acc=0.844\n","[Epoch 32 Batch 60] Loss=0.3077 Acc=0.875\n","[Epoch 32 Batch 80] Loss=0.1775 Acc=0.906\n","[Epoch 32 Batch 100] Loss=0.3418 Acc=0.906\n","[Epoch 32 Batch 120] Loss=0.3819 Acc=0.844\n","[Epoch 32 Batch 140] Loss=0.2885 Acc=0.875\n","[Epoch 32 Batch 160] Loss=0.4858 Acc=0.875\n","[Epoch 32 Batch 180] Loss=0.1611 Acc=0.938\n","[Epoch 32 Batch 200] Loss=0.3092 Acc=0.906\n","[Epoch 32 Batch 220] Loss=0.7725 Acc=0.750\n","[Epoch 32 Batch 240] Loss=0.4314 Acc=0.875\n","[Epoch 32 Batch 260] Loss=0.3249 Acc=0.906\n","[Epoch 32 Batch 280] Loss=0.3132 Acc=0.844\n","[Epoch 32 Batch 300] Loss=0.1190 Acc=1.000\n","--> Train Epoch 32: Loss=0.3009, Acc=0.8970\n","--> Val   Epoch 32: Loss=0.5265, Acc=0.8481\n","  [*] Saved new best model (val_acc=0.8481)\n","[Epoch 33 Batch 0] Loss=0.4289 Acc=0.844\n","[Epoch 33 Batch 20] Loss=0.3945 Acc=0.906\n","[Epoch 33 Batch 40] Loss=0.2725 Acc=0.938\n","[Epoch 33 Batch 60] Loss=0.2478 Acc=0.875\n","[Epoch 33 Batch 80] Loss=0.3519 Acc=0.938\n","[Epoch 33 Batch 100] Loss=0.1857 Acc=0.938\n","[Epoch 33 Batch 120] Loss=0.1529 Acc=0.938\n","[Epoch 33 Batch 140] Loss=0.2846 Acc=0.812\n","[Epoch 33 Batch 160] Loss=0.1461 Acc=0.938\n","[Epoch 33 Batch 180] Loss=0.2667 Acc=0.938\n","[Epoch 33 Batch 200] Loss=0.3046 Acc=0.875\n","[Epoch 33 Batch 220] Loss=0.1981 Acc=0.938\n","[Epoch 33 Batch 240] Loss=0.0912 Acc=0.969\n","[Epoch 33 Batch 260] Loss=0.2882 Acc=0.875\n","[Epoch 33 Batch 280] Loss=0.5372 Acc=0.812\n","[Epoch 33 Batch 300] Loss=0.3686 Acc=0.875\n","--> Train Epoch 33: Loss=0.2843, Acc=0.9019\n","--> Val   Epoch 33: Loss=0.6128, Acc=0.8237\n","[Epoch 34 Batch 0] Loss=0.2566 Acc=0.875\n","[Epoch 34 Batch 20] Loss=0.3234 Acc=0.844\n","[Epoch 34 Batch 40] Loss=0.2368 Acc=0.906\n","[Epoch 34 Batch 60] Loss=0.1604 Acc=0.969\n","[Epoch 34 Batch 80] Loss=0.2341 Acc=0.938\n","[Epoch 34 Batch 100] Loss=0.4723 Acc=0.906\n","[Epoch 34 Batch 120] Loss=0.0632 Acc=0.969\n","[Epoch 34 Batch 140] Loss=0.1253 Acc=0.969\n","[Epoch 34 Batch 160] Loss=0.4509 Acc=0.844\n","[Epoch 34 Batch 180] Loss=0.2142 Acc=0.938\n","[Epoch 34 Batch 200] Loss=0.2393 Acc=0.875\n","[Epoch 34 Batch 220] Loss=0.2898 Acc=0.906\n","[Epoch 34 Batch 240] Loss=0.3440 Acc=0.906\n","[Epoch 34 Batch 260] Loss=0.1537 Acc=0.938\n","[Epoch 34 Batch 280] Loss=0.3719 Acc=0.875\n","[Epoch 34 Batch 300] Loss=0.3647 Acc=0.875\n","--> Train Epoch 34: Loss=0.2963, Acc=0.8975\n","--> Val   Epoch 34: Loss=0.5665, Acc=0.8408\n","[Epoch 35 Batch 0] Loss=0.1536 Acc=0.938\n","[Epoch 35 Batch 20] Loss=0.2851 Acc=0.875\n","[Epoch 35 Batch 40] Loss=0.2613 Acc=0.906\n","[Epoch 35 Batch 60] Loss=0.1988 Acc=0.938\n","[Epoch 35 Batch 80] Loss=0.2774 Acc=0.906\n","[Epoch 35 Batch 100] Loss=0.5926 Acc=0.844\n","[Epoch 35 Batch 120] Loss=0.3526 Acc=0.812\n","[Epoch 35 Batch 140] Loss=0.2411 Acc=0.938\n","[Epoch 35 Batch 160] Loss=0.3282 Acc=0.906\n","[Epoch 35 Batch 180] Loss=0.3803 Acc=0.906\n","[Epoch 35 Batch 200] Loss=0.2032 Acc=0.875\n","[Epoch 35 Batch 220] Loss=0.3494 Acc=0.938\n","[Epoch 35 Batch 240] Loss=0.1506 Acc=0.969\n","[Epoch 35 Batch 260] Loss=0.0554 Acc=1.000\n","[Epoch 35 Batch 280] Loss=0.2065 Acc=0.938\n","[Epoch 35 Batch 300] Loss=0.3376 Acc=0.875\n","--> Train Epoch 35: Loss=0.2842, Acc=0.9003\n","--> Val   Epoch 35: Loss=0.6137, Acc=0.8213\n","[Epoch 36 Batch 0] Loss=0.2826 Acc=0.938\n","[Epoch 36 Batch 20] Loss=0.1928 Acc=0.938\n","[Epoch 36 Batch 40] Loss=0.3588 Acc=0.906\n","[Epoch 36 Batch 60] Loss=0.4948 Acc=0.812\n","[Epoch 36 Batch 80] Loss=0.4786 Acc=0.781\n","[Epoch 36 Batch 100] Loss=0.2418 Acc=0.938\n","[Epoch 36 Batch 120] Loss=0.3526 Acc=0.875\n","[Epoch 36 Batch 140] Loss=0.4887 Acc=0.906\n","[Epoch 36 Batch 160] Loss=0.5478 Acc=0.781\n","[Epoch 36 Batch 180] Loss=0.3256 Acc=0.844\n","[Epoch 36 Batch 200] Loss=0.3948 Acc=0.812\n","[Epoch 36 Batch 220] Loss=0.2207 Acc=0.969\n","[Epoch 36 Batch 240] Loss=0.2517 Acc=0.875\n","[Epoch 36 Batch 260] Loss=0.2475 Acc=0.906\n","[Epoch 36 Batch 280] Loss=0.2272 Acc=0.938\n","[Epoch 36 Batch 300] Loss=0.1404 Acc=0.938\n","--> Train Epoch 36: Loss=0.2824, Acc=0.9023\n","--> Val   Epoch 36: Loss=0.5969, Acc=0.8286\n","[Epoch 37 Batch 0] Loss=0.0846 Acc=1.000\n","[Epoch 37 Batch 20] Loss=0.3318 Acc=0.844\n","[Epoch 37 Batch 40] Loss=0.1969 Acc=0.906\n","[Epoch 37 Batch 60] Loss=0.3606 Acc=0.844\n","[Epoch 37 Batch 80] Loss=0.1730 Acc=0.938\n","[Epoch 37 Batch 100] Loss=0.3706 Acc=0.844\n","[Epoch 37 Batch 120] Loss=0.3222 Acc=0.844\n","[Epoch 37 Batch 140] Loss=0.2674 Acc=0.906\n","[Epoch 37 Batch 160] Loss=0.2757 Acc=0.938\n","[Epoch 37 Batch 180] Loss=0.4611 Acc=0.906\n","[Epoch 37 Batch 200] Loss=0.2915 Acc=0.906\n","[Epoch 37 Batch 220] Loss=0.1629 Acc=0.938\n","[Epoch 37 Batch 240] Loss=0.3659 Acc=0.906\n","[Epoch 37 Batch 260] Loss=0.2270 Acc=0.906\n","[Epoch 37 Batch 280] Loss=0.0970 Acc=0.969\n","[Epoch 37 Batch 300] Loss=0.2321 Acc=0.906\n","--> Train Epoch 37: Loss=0.2814, Acc=0.9044\n","--> Val   Epoch 37: Loss=0.5326, Acc=0.8436\n","[Epoch 38 Batch 0] Loss=0.2326 Acc=0.969\n","[Epoch 38 Batch 20] Loss=0.1499 Acc=0.969\n","[Epoch 38 Batch 40] Loss=0.2723 Acc=0.875\n","[Epoch 38 Batch 60] Loss=0.4773 Acc=0.875\n","[Epoch 38 Batch 80] Loss=0.2078 Acc=0.938\n","[Epoch 38 Batch 100] Loss=0.1136 Acc=0.938\n","[Epoch 38 Batch 120] Loss=0.2585 Acc=0.938\n","[Epoch 38 Batch 140] Loss=0.2601 Acc=0.875\n","[Epoch 38 Batch 160] Loss=0.3323 Acc=0.844\n","[Epoch 38 Batch 180] Loss=0.2872 Acc=0.875\n","[Epoch 38 Batch 200] Loss=0.0372 Acc=1.000\n","[Epoch 38 Batch 220] Loss=0.3564 Acc=0.906\n","[Epoch 38 Batch 240] Loss=0.2007 Acc=0.938\n","[Epoch 38 Batch 260] Loss=0.2566 Acc=0.906\n","[Epoch 38 Batch 280] Loss=0.2059 Acc=0.906\n","[Epoch 38 Batch 300] Loss=0.1971 Acc=0.938\n","--> Train Epoch 38: Loss=0.2669, Acc=0.9062\n","--> Val   Epoch 38: Loss=0.5521, Acc=0.8448\n","[Epoch 39 Batch 0] Loss=0.0746 Acc=1.000\n","[Epoch 39 Batch 20] Loss=0.3568 Acc=0.906\n","[Epoch 39 Batch 40] Loss=0.1536 Acc=0.938\n","[Epoch 39 Batch 60] Loss=0.3389 Acc=0.906\n","[Epoch 39 Batch 80] Loss=0.1312 Acc=0.906\n","[Epoch 39 Batch 100] Loss=0.4120 Acc=0.906\n","[Epoch 39 Batch 120] Loss=0.2791 Acc=0.906\n","[Epoch 39 Batch 140] Loss=0.2234 Acc=0.938\n","[Epoch 39 Batch 160] Loss=0.2742 Acc=0.844\n","[Epoch 39 Batch 180] Loss=0.2558 Acc=0.875\n"]}],"source":["# 4. train\n","# 9m 53s without cache 1 epoch\n","# 9m 13s with cache 1 epoch\n","# 5m 18s with voxelizer vectorize level 1\n","dataset_name = config[\"dataset\"][\"name\"]\n","# add timestamp to the name of the output directory\n","import datetime\n","timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","output_dir = f\"output_{timestamp}\"\n","os.makedirs(f\"{output_dir}\", exist_ok=True)\n","trainer.fit(save_path=f\"{output_dir}/pointpillars_{dataset_name}.pth\")"]},{"cell_type":"code","execution_count":null,"id":"620423f6","metadata":{"id":"620423f6"},"outputs":[],"source":["# 5. plots for report\n","trainer.plot_history()"]},{"cell_type":"code","execution_count":null,"id":"a3c99099","metadata":{"id":"a3c99099"},"outputs":[],"source":["# 6. save artifacts\n","\n","trainer.save_curves_and_config(output_dir=output_dir)"]},{"cell_type":"code","execution_count":null,"id":"3916d9d3","metadata":{"id":"3916d9d3"},"outputs":[],"source":["import csv\n","\n","new_row = {\n","\n","    \"timestamp\": timestamp,\n","    \"name\": config[\"dataset\"][\"name\"],\n","    \"num_classes\": config[\"dataset\"][\"num_classes\"],\n","    \"num_points\": config[\"dataset\"][\"num_points\"],\n","    \"pillar_size\": config[\"voxelizer\"][\"pillar_size\"],\n","    \"max_pillars\": config[\"voxelizer\"][\"max_pillars\"],\n","    \"max_points_per_pillar\": config[\"voxelizer\"][\"max_points_per_pillar\"],\n","    \"pfn_out_dim\": config[\"pfn\"][\"out_dim\"],\n","    \"bb_base_channels\": config[\"backbone\"][\"base_channels\"],\n","    \"bb_fc1_dim\": config[\"backbone\"][\"fc1_dim\"],\n","    \"bb_dropout_p\": config[\"backbone\"][\"dropout_p\"],\n","    \"batch_size\": config[\"train\"][\"batch_size\"],\n","    \"lr\": config[\"train\"][\"lr\"],\n","    \"weight_decay\": config[\"train\"][\"weight_decay\"],\n","    \"num_epochs\": config[\"train\"][\"num_epochs\"],\n","    \"min_train_loss\": min(trainer.history[\"train_loss\"]),\n","    \"min_val_loss\": min(trainer.history[\"val_loss\"]),\n","    \"max_train_acc\": max(trainer.history[\"train_acc\"]),\n","    \"max_val_acc\": max(trainer.history[\"val_acc\"])\n","}\n","\n","csv_path = \"config_log.csv\"\n","\n","# Append mode\n","with open(csv_path, \"a\", newline=\"\") as f:\n","    writer = csv.DictWriter(f, fieldnames=new_row.keys())\n","\n","    # Write header only if file is empty\n","    if f.tell() == 0:\n","        writer.writeheader()\n","\n","    writer.writerow(new_row)\n"]},{"cell_type":"code","execution_count":null,"id":"a8cb0fc3","metadata":{"id":"a8cb0fc3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d5595708-b59f-4b85-993b-c003f0752eea","metadata":{"id":"d5595708-b59f-4b85-993b-c003f0752eea"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python [conda env:CS7643Final]","language":"python","name":"conda-env-CS7643Final-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.19"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}