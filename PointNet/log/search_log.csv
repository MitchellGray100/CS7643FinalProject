model_name,batch_size,num_epochs,learning_rate,learning_rate_decay_step,learning_rate_decay_factor,min_learning_rate,regularization_loss_weight,dropout_prob,adam_weight_decay,augment_training_data,num_points,batch_norm_init_decay,batch_norm_decay_rate,batch_norm_decay_step,batch_norm_decay_clip
ModelNet10,32,250,0.001,2500,0.7,0.0,0.001,0.5,0.0,1,1024,0.5,0.5,2500,0.99
ModelNet10,32,200,0.001,80000,0.7,0.0,0.001,0.5,0.0,1,1024,0.5,0.5,8000,0.99
ModelNet10,32,10,0.001,80000,0.7,0.0,0.001,0.5,0.0,1,1024,0.5,0.5,8000,0.99
ModelNet10,32,10,0.001,80000,0.7,0.0,0.001,0.4,0.0,1,1024,0.5,0.5,8000,0.99
ModelNet10,32,200,0.001,80000,0.7,0.0,0.001,0.4,0.0,1,1024,0.5,0.5,8000,0.99
